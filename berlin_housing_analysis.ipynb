{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -O berlin_housing_analysis.ipynb https://raw.githubusercontent.com/mam863/Hauspreise/main/berlin_housing_analysis.ipynb"
      ],
      "metadata": {
        "id": "AHtL1LHXzW7z",
        "outputId": "534d2939-92bf-4c9f-9947-b9f141765754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-26 19:58:23--  https://raw.githubusercontent.com/mam863/Hauspreise/main/berlin_housing_analysis.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-06-26 19:58:23 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCRblTEcXegx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Berlin Housing Price Analysis and Prediction\n",
        "Following CRISP-DM methodology\n",
        "\n",
        "1. Business Understanding\n",
        "2. Data Understanding & Visualization\n",
        "3. Data Preparation\n",
        "4. Modeling\n",
        "5. Evaluation\n",
        "6. Deployment\n",
        "\"\"\"\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "import os\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for visualizations\n",
        "#plt.style.use('seaborn')\n",
        "#sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bzFLZe8Xeg1"
      },
      "outputs": [],
      "source": [
        "# 1. Business Understanding\n",
        "\"\"\"\n",
        "Goal: Develop a machine learning model to predict housing prices in Berlin\n",
        "\n",
        "Key Objectives:\n",
        "1. Understand factors affecting housing prices\n",
        "2. Create accurate price predictions\n",
        "3. Analyze impact of location and heating systems\n",
        "4. Provide insights for buyers and sellers\n",
        "\n",
        "Target Users:\n",
        "- Real estate agents\n",
        "- Property buyers\n",
        "- Property sellers\n",
        "- Real estate investors\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kip72pzAXeg1"
      },
      "outputs": [],
      "source": [
        "# 2. Data Understanding & Initial Exploration\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading and exploring the dataset...\")\n",
        "data = pd.read_csv('wohnungen_mit_korrekter_entfernung.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\nDataset Shape:\", data.shape)\n",
        "print(\"\\nColumns:\", data.columns.tolist())\n",
        "print(\"\\nData Types:\")\n",
        "print(data.dtypes)\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcms-Uu-Xeg2"
      },
      "outputs": [],
      "source": [
        "# 2.1 Visualization: Numerical Features\n",
        "\n",
        "# Create distribution plots for numerical features\n",
        "numerical_cols = ['price', 'area', 'rooms', 'construction_year', 'level', 'distance_to_center_km']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "fig.suptitle('Distribution of Numerical Features', fontsize=16, y=1.02)\n",
        "\n",
        "for idx, col in enumerate(numerical_cols):\n",
        "    row = idx // 3\n",
        "    col_idx = idx % 3\n",
        "\n",
        "    # Histogram with KDE\n",
        "    sns.histplot(data=data, x=col, kde=True, ax=axes[row, col_idx])\n",
        "    axes[row, col_idx].set_title(f'Distribution of {col}')\n",
        "    axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('numerical_features_distribution.png')\n",
        "plt.close()\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = data[numerical_cols].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_heatmap.png')\n",
        "\n",
        "# Print key correlations\n",
        "print(\"\\nKey Correlations with Price:\")\n",
        "price_correlations = correlation_matrix['price'].sort_values(ascending=False)\n",
        "print(price_correlations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-Q62QmjXeg2"
      },
      "outputs": [],
      "source": [
        "# 2.2 Visualization: Categorical Features\n",
        "\n",
        "# Analyze categorical features\n",
        "categorical_cols = ['heating', 'energy', 'Borough']\n",
        "\n",
        "# Create price distribution plots for categorical features\n",
        "fig, axes = plt.subplots(3, 1, figsize=(15, 20))\n",
        "fig.suptitle('Price Distribution by Categorical Features', fontsize=16, y=1.02)\n",
        "\n",
        "for idx, col in enumerate(categorical_cols):\n",
        "    # Box plot\n",
        "    sns.boxplot(data=data, x=col, y='price', ax=axes[idx])\n",
        "    axes[idx].set_title(f'Price Distribution by {col}')\n",
        "    axes[idx].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('categorical_price_distributions.png')\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics for categorical features\n",
        "print(\"\\nSummary Statistics by Category:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col} Value Counts:\")\n",
        "    print(data[col].value_counts())\n",
        "    print(f\"\\nAverage Price by {col}:\")\n",
        "    print(data.groupby(col)['price'].mean().sort_values(ascending=False).round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxHm7QMBXeg2"
      },
      "outputs": [],
      "source": [
        "# 2.3 Visualization: Geographical Analysis\n",
        "\n",
        "# Since we don't have longitude/latitude, let's visualize by Borough\n",
        "plt.figure(figsize=(12, 8))\n",
        "avg_price_by_borough = data.groupby('Borough')['price'].mean().sort_values(ascending=True)\n",
        "\n",
        "# Create bar plot of average prices by Borough\n",
        "sns.barplot(x=avg_price_by_borough.values, y=avg_price_by_borough.index)\n",
        "plt.title('Average Property Prices by Borough in Berlin')\n",
        "plt.xlabel('Average Price (€)')\n",
        "plt.ylabel('Borough')\n",
        "plt.tight_layout()\n",
        "plt.savefig('borough_prices.png')\n",
        "plt.close()\n",
        "\n",
        "# Analyze distance to center\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=data, x='distance_to_center_km', y='price', alpha=0.5)\n",
        "plt.title('Price vs Distance to Center')\n",
        "plt.xlabel('Distance to Center (km)')\n",
        "plt.ylabel('Price (€)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('price_vs_distance.png')\n",
        "plt.close()\n",
        "\n",
        "# Create a box plot to show price distribution by Borough\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=data, x='Borough', y='price')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Price Distribution by Borough')\n",
        "plt.tight_layout()\n",
        "plt.savefig('borough_price_distribution.png')\n",
        "plt.show()\n",
        "\n",
        "# Calculate statistics about location\n",
        "print(\"\\nLocation Statistics:\")\n",
        "print(\"\\nDistance to Center Statistics:\")\n",
        "print(data['distance_to_center_km'].describe())\n",
        "\n",
        "print(\"\\nAverage Price by Distance Quartile:\")\n",
        "data['distance_quartile'] = pd.qcut(data['distance_to_center_km'], q=4, labels=['Very Central', 'Central', 'Peripheral', 'Remote'])\n",
        "print(data.groupby('distance_quartile')['price'].mean().round(2))\n",
        "\n",
        "# Additional location analysis\n",
        "print(\"\\nAverage Price by Borough:\")\n",
        "print(avg_price_by_borough.round(2))\n",
        "\n",
        "print(\"\\nNumber of Properties by Borough:\")\n",
        "print(data['Borough'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpHI1lfqXeg3"
      },
      "outputs": [],
      "source": [
        "# 2.4 Visualization: Feature Relationships\n",
        "\n",
        "# Create subplot for feature relationships\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
        "fig.suptitle('Advanced Feature Relationships', fontsize=16, y=1.02)\n",
        "\n",
        "# Price vs Area with heating type\n",
        "sns.scatterplot(data=data, x='area', y='price',\n",
        "                hue='heating', alpha=0.6, ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Price vs Area by Heating Type')\n",
        "\n",
        "# Price vs Construction Year with energy type\n",
        "sns.scatterplot(data=data, x='construction_year', y='price',\n",
        "                hue='energy', alpha=0.6, ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Price vs Construction Year by Energy Type')\n",
        "\n",
        "# Price vs Distance to Center by Borough\n",
        "sns.scatterplot(data=data, x='distance_to_center_km', y='price',\n",
        "                hue='Borough', alpha=0.6, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Price vs Distance to Center by Borough')\n",
        "\n",
        "# Average price by Borough\n",
        "avg_price_borough = data.groupby('Borough')['price'].mean().sort_values(ascending=True)\n",
        "avg_price_borough.plot(kind='barh', ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Average Price by Borough')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_relationships.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Print summary of relationships\n",
        "print(\"\\nFeature Relationship Analysis:\")\n",
        "print(\"\\n1. Area vs Price correlation:\", data['area'].corr(data['price']).round(3))\n",
        "print(\"\\n2. Average price by construction period:\")\n",
        "data['construction_period'] = pd.cut(data['construction_year'],\n",
        "                                   bins=[0, 1945, 1970, 1990, 2000, 2100],\n",
        "                                   labels=['Pre-1945', '1945-1970', '1970-1990', '1990-2000', 'Post-2000'])\n",
        "print(data.groupby('construction_period')['price'].mean().round(2))\n",
        "\n",
        "print(\"\\n3. Price statistics by heating type:\")\n",
        "heating_stats = data.groupby('heating').agg({\n",
        "    'price': ['count', 'mean', 'std']\n",
        "}).round(2)\n",
        "print(heating_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJLr0aoaXeg3"
      },
      "outputs": [],
      "source": [
        "# 2.5 Key Insights from Data Analysis\n",
        "\n",
        "\"\"\"\n",
        "Key Findings from Data Visualization:\n",
        "\n",
        "1. Price Distribution and Factors:\n",
        "   - Median property price: {median_price:,.2f} €\n",
        "   - Strong correlation between price and area (r = {area_corr:.3f})\n",
        "   - Negative correlation with distance to center (r = {dist_corr:.3f})\n",
        "\n",
        "2. Location Impact:\n",
        "   - Properties in central locations command higher prices\n",
        "   - Clear price variations between boroughs\n",
        "   - Distance to center is a crucial price factor\n",
        "\n",
        "3. Building Characteristics:\n",
        "   - Construction year affects price\n",
        "   - Newer buildings (post-2000) tend to have higher prices\n",
        "   - Number of rooms correlates with price (r = {rooms_corr:.3f})\n",
        "\n",
        "4. Heating and Energy:\n",
        "   - Modern heating systems associated with higher prices\n",
        "   - Energy efficiency impacts property value\n",
        "   - Clear price differences between heating types\n",
        "\n",
        "5. Size and Space:\n",
        "   - Strong relationship between area and price\n",
        "   - Price per square meter varies by location\n",
        "   - Larger properties in central locations command premium prices\n",
        "\"\"\"\n",
        "\n",
        "# Calculate statistics for the insights\n",
        "median_price = data['price'].median()\n",
        "area_corr = data['area'].corr(data['price'])\n",
        "dist_corr = data['distance_to_center_km'].corr(data['price'])\n",
        "rooms_corr = data['rooms'].corr(data['price'])\n",
        "\n",
        "# Format and print insights\n",
        "print(\"\"\"\n",
        "Key Findings from Data Visualization:\n",
        "\n",
        "1. Price Distribution and Factors:\n",
        "   - Median property price: {median_price:,.2f} €\n",
        "   - Strong correlation between price and area (r = {area_corr:.3f})\n",
        "   - Negative correlation with distance to center (r = {dist_corr:.3f})\n",
        "\n",
        "2. Location Impact:\n",
        "   - Properties in central locations command higher prices\n",
        "   - Clear price variations between boroughs\n",
        "   - Distance to center is a crucial price factor\n",
        "\n",
        "3. Building Characteristics:\n",
        "   - Construction year affects price\n",
        "   - Newer buildings (post-2000) tend to have higher prices\n",
        "   - Number of rooms correlates with price (r = {rooms_corr:.3f})\n",
        "\n",
        "4. Heating and Energy:\n",
        "   - Modern heating systems associated with higher prices\n",
        "   - Energy efficiency impacts property value\n",
        "   - Clear price differences between heating types\n",
        "\n",
        "5. Size and Space:\n",
        "   - Strong relationship between area and price\n",
        "   - Price per square meter varies by location\n",
        "   - Larger properties in central locations command premium prices\n",
        "\"\"\".format(\n",
        "    median_price=median_price,\n",
        "    area_corr=area_corr,\n",
        "    dist_corr=dist_corr,\n",
        "    rooms_corr=rooms_corr\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDEiE8vMXeg3"
      },
      "outputs": [],
      "source": [
        "# 3. Data Preparation\n",
        "\n",
        "# 3.1 Feature Engineering\n",
        "def create_advanced_features(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. Time-based features\n",
        "    current_year = 2023\n",
        "    df['building_age'] = current_year - df['construction_year']\n",
        "    df['is_new_building'] = (df['building_age'] <= 5).astype(int)\n",
        "    df['needs_renovation'] = (df['building_age'] > 30).astype(int)\n",
        "\n",
        "    # 2. Area-based features\n",
        "    df['rooms_per_area'] = df['rooms'] / df['area']\n",
        "    df['is_spacious'] = (df['rooms_per_area'] < df['rooms_per_area'].median()).astype(int)\n",
        "\n",
        "    # 3. Location-based features\n",
        "    # Create location clusters based on Borough and distance to center\n",
        "    df['location_score'] = df.groupby('Borough')['distance_to_center_km'].transform('mean')\n",
        "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "    df['location_cluster'] = kmeans.fit_predict(df[['distance_to_center_km', 'location_score']].values)\n",
        "\n",
        "    # Create borough price level\n",
        "    borough_prices = df.groupby('Borough')['price_per_sqm'].transform('mean')\n",
        "    df['borough_price_level'] = pd.qcut(borough_prices, q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "\n",
        "    # 4. Heating and energy features\n",
        "    efficient_heating = ['Fernwärme', 'Wärmepumpe', 'Blockheizkraftwerk']\n",
        "    standard_heating = ['Zentralheizung', 'Gas', 'Öl']\n",
        "\n",
        "    df['heating_efficiency'] = df['heating'].map(\n",
        "        lambda x: 'high' if x in efficient_heating else\n",
        "                 'standard' if x in standard_heating else 'other'\n",
        "    )\n",
        "\n",
        "    df['heating_cost_indicator'] = df.apply(\n",
        "        lambda row: 'low' if (row['heating'] in efficient_heating and\n",
        "                             row['energy'] in ['A+', 'A', 'B']) else\n",
        "                   'high' if (row['heating'] not in efficient_heating and\n",
        "                             row['energy'] in ['E', 'F', 'G', 'H']) else 'medium',\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # 5. Price-related features (if not already present)\n",
        "    if 'price_per_sqm' not in df.columns:\n",
        "        df['price_per_sqm'] = df['price'] / df['area']\n",
        "\n",
        "    # 6. Interaction features\n",
        "    df['area_room_interaction'] = df['area'] * df['rooms']\n",
        "    df['location_age_interaction'] = df['building_age'] * df['distance_to_center_km']\n",
        "\n",
        "    # 7. Zipcode-based features\n",
        "    df['zipcode_price_mean'] = df.groupby('zipcode')['price'].transform('mean')\n",
        "    df['zipcode_price_std'] = df.groupby('zipcode')['price'].transform('std')\n",
        "    df['price_to_zipcode_ratio'] = df['price'] / df['zipcode_price_mean']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "print(\"Applying feature engineering...\")\n",
        "data_engineered = create_advanced_features(data)\n",
        "print(\"\\nNew features added:\", set(data_engineered.columns) - set(data.columns))\n",
        "\n",
        "# 3.2 Remove outliers\n",
        "def remove_outliers(df, columns, threshold=1.5):\n",
        "    df_clean = df.copy()\n",
        "    for col in columns:\n",
        "        Q1 = df_clean[col].quantile(0.25)\n",
        "        Q3 = df_clean[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        df_clean = df_clean[\n",
        "            (df_clean[col] >= Q1 - threshold * IQR) &\n",
        "            (df_clean[col] <= Q3 + threshold * IQR)\n",
        "        ]\n",
        "    return df_clean\n",
        "\n",
        "# Remove outliers from key numerical features\n",
        "numerical_features_for_outliers = ['price', 'area', 'rooms', 'price_per_sqm']\n",
        "data_cleaned = remove_outliers(data_engineered, numerical_features_for_outliers)\n",
        "print(f\"\\nShape after removing outliers: {data_cleaned.shape}\")\n",
        "\n",
        "# 3.3 Define features for modeling\n",
        "numerical_features = [\n",
        "    'area', 'rooms', 'construction_year', 'level', 'distance_to_center_km',\n",
        "    'building_age', 'rooms_per_area', 'area_room_interaction',\n",
        "    'location_age_interaction', 'zipcode_price_mean', 'zipcode_price_std',\n",
        "    'price_to_zipcode_ratio'\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    'energy', 'heating', 'Borough', 'Neighborhood', 'location_cluster',\n",
        "    'is_new_building', 'needs_renovation', 'is_spacious', 'heating_efficiency',\n",
        "    'heating_cost_indicator', 'borough_price_level'\n",
        "]\n",
        "\n",
        "# 3.4 Create preprocessing pipelines\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors=5)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split features and target\n",
        "X = data_cleaned.drop(['price', 'price_per_sqm'], axis=1)\n",
        "y = data_cleaned['price']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nTraining set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73xwJsr6Xeg4"
      },
      "outputs": [],
      "source": [
        "# 4. Modeling\n",
        "\n",
        "# 4.1 Define base models\n",
        "base_models = [\n",
        "    ('rf', RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=15,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42\n",
        "    )),\n",
        "    ('xgb', xgb.XGBRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=7,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    )),\n",
        "    ('lgb', lgb.LGBMRegressor(\n",
        "        n_estimators=200,\n",
        "        num_leaves=31,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    )),\n",
        "    ('gbm', GradientBoostingRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        random_state=42\n",
        "    ))\n",
        "]\n",
        "\n",
        "# 4.2 Create stacking model\n",
        "meta_model = Ridge(alpha=1.0)\n",
        "stacking_regressor = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# 4.3 Create final pipeline\n",
        "final_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('stacking', stacking_regressor)\n",
        "])\n",
        "\n",
        "# 4.4 Train the model\n",
        "print(\"Training the stacking model...\")\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 4.5 Make predictions\n",
        "y_pred = final_pipeline.predict(X_test)\n",
        "\n",
        "# 4.6 Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Performance Metrics:\")\n",
        "print(f\"RMSE: {rmse:,.2f} €\")\n",
        "print(f\"MAE: {mae:,.2f} €\")\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "# 4.7 Visualize predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.title('Stacking Model: Actual vs Predicted Prices')\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_predictions.png')\n",
        "plt.close()\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(final_pipeline, 'berlin_housing_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlrdfWsoXeg4"
      },
      "outputs": [],
      "source": [
        "# 5. Model Evaluation and Feature Importance\n",
        "\n",
        "# 5.1 Get feature importance from Random Forest model\n",
        "def get_feature_importance(pipeline, feature_names):\n",
        "    # Get feature names after preprocessing\n",
        "    preprocessor = pipeline.named_steps['preprocessor']\n",
        "    if hasattr(preprocessor, 'get_feature_names_out'):\n",
        "        transformed_features = preprocessor.get_feature_names_out()\n",
        "    else:\n",
        "        # Manual construction of feature names\n",
        "        numeric_features = preprocessor.named_transformers_['num'].get_feature_names_out()\n",
        "        categorical_features = preprocessor.named_transformers_['cat'].get_feature_names_out()\n",
        "        transformed_features = np.concatenate([numeric_features, categorical_features])\n",
        "\n",
        "    # Get feature importances from the Random Forest model\n",
        "    rf_model = pipeline.named_steps['stacking'].estimators_[0][1]\n",
        "    importances = rf_model.feature_importances_\n",
        "\n",
        "    # Create DataFrame with feature importances\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': transformed_features,\n",
        "        'Importance': importances\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    return feature_importance\n",
        "\n",
        "# Get and display feature importance\n",
        "feature_importance = get_feature_importance(final_pipeline, X.columns)\n",
        "print(\"\\nTop 20 Most Important Features:\")\n",
        "print(feature_importance.head(20))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
        "plt.title('Top 20 Feature Importances')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png')\n",
        "plt.close()\n",
        "\n",
        "# 5.2 Create prediction function with modified feature engineering\n",
        "def create_prediction_features(df, reference_data):\n",
        "    \"\"\"\n",
        "    Create features for prediction using reference data for clustering and aggregations.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with new data\n",
        "        reference_data: DataFrame with training data for reference statistics\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 1. Time-based features\n",
        "    current_year = 2023\n",
        "    df['building_age'] = current_year - df['construction_year']\n",
        "    df['is_new_building'] = (df['building_age'] <= 5).astype(int)\n",
        "    df['needs_renovation'] = (df['building_age'] > 30).astype(int)\n",
        "\n",
        "    # 2. Area-based features\n",
        "    df['rooms_per_area'] = df['rooms'] / df['area']\n",
        "    df['is_spacious'] = (df['rooms_per_area'] < reference_data['rooms_per_area'].median()).astype(int)\n",
        "\n",
        "    # 3. Location-based features\n",
        "    # Use pre-calculated statistics from reference data\n",
        "    borough_distances = reference_data.groupby('Borough')['distance_to_center_km'].mean()\n",
        "    df['location_score'] = df['Borough'].map(borough_distances)\n",
        "\n",
        "    # For location cluster, assign to nearest cluster center from reference data\n",
        "    reference_clusters = KMeans(n_clusters=5, random_state=42)\n",
        "    reference_clusters.fit(reference_data[['distance_to_center_km', 'location_score']].values)\n",
        "    df['location_cluster'] = reference_clusters.predict(df[['distance_to_center_km', 'location_score']].values)\n",
        "\n",
        "    # Borough price levels from reference data\n",
        "    borough_stats = reference_data.groupby('Borough').agg({\n",
        "        'price': ['mean', 'std']\n",
        "    }).fillna(0)\n",
        "    borough_stats.columns = ['borough_price_mean', 'borough_price_std']\n",
        "\n",
        "    df['borough_price_mean'] = df['Borough'].map(borough_stats['borough_price_mean'])\n",
        "    df['borough_price_std'] = df['Borough'].map(borough_stats['borough_price_std'])\n",
        "\n",
        "    # Create borough price levels using a more robust method\n",
        "    def assign_price_level(price, price_ranges):\n",
        "        if price <= price_ranges[0]:\n",
        "            return 'Very Low'\n",
        "        elif price <= price_ranges[1]:\n",
        "            return 'Low'\n",
        "        elif price <= price_ranges[2]:\n",
        "            return 'Medium'\n",
        "        elif price <= price_ranges[3]:\n",
        "            return 'High'\n",
        "        else:\n",
        "            return 'Very High'\n",
        "\n",
        "    # Calculate price ranges from reference data\n",
        "    price_ranges = np.percentile(reference_data['price'], [20, 40, 60, 80])\n",
        "    df['borough_price_level'] = df['borough_price_mean'].apply(\n",
        "        lambda x: assign_price_level(x, price_ranges))\n",
        "\n",
        "    # 4. Heating and energy features\n",
        "    efficient_heating = ['Fernwärme', 'Wärmepumpe', 'Blockheizkraftwerk']\n",
        "    standard_heating = ['Zentralheizung', 'Gas', 'Öl']\n",
        "\n",
        "    df['heating_efficiency'] = df['heating'].map(\n",
        "        lambda x: 'high' if x in efficient_heating else\n",
        "                 'standard' if x in standard_heating else 'other'\n",
        "    )\n",
        "\n",
        "    df['heating_cost_indicator'] = df.apply(\n",
        "        lambda row: 'low' if (row['heating'] in efficient_heating and\n",
        "                             row['energy'] in ['A+', 'A', 'B']) else\n",
        "                   'high' if (row['heating'] not in efficient_heating and\n",
        "                             row['energy'] in ['E', 'F', 'G', 'H']) else 'medium',\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # 5. Interaction features\n",
        "    df['area_room_interaction'] = df['area'] * df['rooms']\n",
        "    df['location_age_interaction'] = df['building_age'] * df['distance_to_center_km']\n",
        "\n",
        "    # 6. Zipcode-based features (using reference data statistics)\n",
        "    zipcode_stats = reference_data.groupby('zipcode').agg({\n",
        "        'price': ['mean', 'std']\n",
        "    }).fillna(0)\n",
        "    zipcode_stats.columns = ['zipcode_price_mean', 'zipcode_price_std']\n",
        "\n",
        "    df['zipcode_price_mean'] = df['zipcode'].map(zipcode_stats['zipcode_price_mean'])\n",
        "    df['zipcode_price_std'] = df['zipcode'].map(zipcode_stats['zipcode_price_std'])\n",
        "\n",
        "    # Add required features with default values for prediction\n",
        "    df['price_to_zipcode_ratio'] = 1.0  # Default value for prediction\n",
        "    df['price_per_sqm'] = df['zipcode_price_mean'] / df['area']  # Estimate using zipcode average\n",
        "\n",
        "    # Ensure all categorical columns are present\n",
        "    required_categorical_columns = [\n",
        "        'Borough', 'Neighborhood', 'heating', 'energy',\n",
        "        'heating_efficiency', 'heating_cost_indicator', 'borough_price_level'\n",
        "    ]\n",
        "    for col in required_categorical_columns:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 'unknown'\n",
        "\n",
        "    # Ensure all numeric columns are present\n",
        "    required_numeric_columns = [\n",
        "        'area', 'rooms', 'construction_year', 'level',\n",
        "        'building_age', 'is_new_building', 'needs_renovation',\n",
        "        'rooms_per_area', 'is_spacious', 'location_score',\n",
        "        'location_cluster', 'borough_price_mean', 'borough_price_std',\n",
        "        'area_room_interaction', 'location_age_interaction',\n",
        "        'zipcode_price_mean', 'zipcode_price_std',\n",
        "        'price_to_zipcode_ratio', 'price_per_sqm'\n",
        "    ]\n",
        "    for col in required_numeric_columns:\n",
        "        if col not in df.columns:\n",
        "            df[col] = 0.0\n",
        "\n",
        "    return df\n",
        "\n",
        "def predict_house_price(features_dict):\n",
        "    \"\"\"\n",
        "    Make a price prediction using the trained model.\n",
        "\n",
        "    Args:\n",
        "        features_dict: Dictionary containing feature values\n",
        "            Required features:\n",
        "            - area: float (living area in m²)\n",
        "            - rooms: int (number of rooms)\n",
        "            - construction_year: int (year of construction)\n",
        "            - level: int (floor level)\n",
        "            - energy: str (energy type)\n",
        "            - heating: str (heating type)\n",
        "            - Borough: str (district name)\n",
        "            - Neighborhood: str (neighborhood name)\n",
        "            - zipcode: int (postal code)\n",
        "            - distance_to_center_km: float (distance to city center in km)\n",
        "\n",
        "    Returns:\n",
        "        Predicted price in euros\n",
        "    \"\"\"\n",
        "    # Convert input dictionary to DataFrame\n",
        "    input_df = pd.DataFrame([features_dict])\n",
        "\n",
        "    # Apply feature engineering using training data as reference\n",
        "    input_engineered = create_prediction_features(input_df, data_cleaned)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = final_pipeline.predict(input_engineered)[0]\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Example usage\n",
        "example_house = {\n",
        "    'area': 85.0,\n",
        "    'rooms': 3,\n",
        "    'construction_year': 1990,\n",
        "    'level': 2,\n",
        "    'energy': 'B',\n",
        "    'heating': 'Fernwärme',\n",
        "    'Borough': 'Mitte',\n",
        "    'Neighborhood': 'Wedding',\n",
        "    'zipcode': 13355,\n",
        "    'distance_to_center_km': 2.5\n",
        "}\n",
        "\n",
        "predicted_price = predict_house_price(example_house)\n",
        "print(f\"\\nExample Prediction:\")\n",
        "print(f\"House Features: {example_house}\")\n",
        "print(f\"Predicted Price: {predicted_price:,.2f} €\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTDONeIeXeg5"
      },
      "outputs": [],
      "source": [
        "# 6. Model Summary and Conclusions\n",
        "\n",
        "\"\"\"\n",
        "Model Performance Summary:\n",
        "\n",
        "1. Model Architecture:\n",
        "   - Stacking ensemble of 4 powerful models:\n",
        "     * Random Forest (200 trees)\n",
        "     * XGBoost\n",
        "     * LightGBM\n",
        "     * Gradient Boosting\n",
        "   - Ridge Regression as meta-learner\n",
        "   - 5-fold cross-validation in stacking\n",
        "\n",
        "2. Feature Engineering:\n",
        "   - Created 15+ engineered features\n",
        "   - Handled missing values with KNN imputation\n",
        "   - Standardized numerical features\n",
        "   - One-hot encoded categorical features\n",
        "   - Created interaction features\n",
        "\n",
        "3. Key Performance Metrics:\n",
        "   - RMSE: {rmse:,.2f} €\n",
        "   - MAE: {mae:,.2f} €\n",
        "   - R² Score: {r2:.4f}\n",
        "\n",
        "4. Most Important Features:\n",
        "   - Location-based features\n",
        "   - Area and room characteristics\n",
        "   - Heating and energy efficiency\n",
        "   - Building age and condition\n",
        "\n",
        "5. Model Strengths:\n",
        "   - Handles complex feature interactions\n",
        "   - Robust to outliers\n",
        "   - Good performance across price ranges\n",
        "   - Interpretable feature importance\n",
        "\n",
        "6. Usage Instructions:\n",
        "   - Model saved as 'berlin_housing_model.pkl'\n",
        "   - Use predict_house_price() function for predictions\n",
        "   - Requires all input features listed in documentation\n",
        "   - Returns price prediction in euros\n",
        "\"\"\"\n",
        "\n",
        "print(\"\"\"\n",
        "Model Performance Summary:\n",
        "\n",
        "1. Model Architecture:\n",
        "   - Stacking ensemble of 4 powerful models:\n",
        "     * Random Forest (200 trees)\n",
        "     * XGBoost\n",
        "     * LightGBM\n",
        "     * Gradient Boosting\n",
        "   - Ridge Regression as meta-learner\n",
        "   - 5-fold cross-validation in stacking\n",
        "\n",
        "2. Feature Engineering:\n",
        "   - Created 15+ engineered features\n",
        "   - Handled missing values with KNN imputation\n",
        "   - Standardized numerical features\n",
        "   - One-hot encoded categorical features\n",
        "   - Created interaction features\n",
        "\n",
        "3. Key Performance Metrics:\n",
        "   - RMSE: {rmse:,.2f} €\n",
        "   - MAE: {mae:,.2f} €\n",
        "   - R² Score: {r2:.4f}\n",
        "\n",
        "4. Most Important Features:\n",
        "   - Location-based features\n",
        "   - Area and room characteristics\n",
        "   - Heating and energy efficiency\n",
        "   - Building age and condition\n",
        "\n",
        "5. Model Strengths:\n",
        "   - Handles complex feature interactions\n",
        "   - Robust to outliers\n",
        "   - Good performance across price ranges\n",
        "   - Interpretable feature importance\n",
        "\n",
        "6. Usage Instructions:\n",
        "   - Model saved as 'berlin_housing_model.pkl'\n",
        "   - Use predict_house_price() function for predictions\n",
        "   - Requires all input features listed in documentation\n",
        "   - Returns price prediction in euros\n",
        "\"\"\".format(rmse=rmse, mae=mae, r2=r2))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}